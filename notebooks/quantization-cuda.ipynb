{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b0b832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/music/lib/python3.12/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c79050f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>function</th>\n",
       "      <th>version_data</th>\n",
       "      <th>diff_code</th>\n",
       "      <th>diff_docstring</th>\n",
       "      <th>whitespace_only_code</th>\n",
       "      <th>whitespace_only_docstring</th>\n",
       "      <th>file_path</th>\n",
       "      <th>filename</th>\n",
       "      <th>project</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tests_test_database.py</td>\n",
       "      <td>test_timewindows</td>\n",
       "      <td>[{'commit_date_time': '2021-08-09 21:00:11+02:...</td>\n",
       "      <td>def test_timewindows(database):\\n        \\n-...</td>\n",
       "      <td>- unit tests for addNewTW and getFirstTWforPro...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tests/test_database.py</td>\n",
       "      <td>test_database.py</td>\n",
       "      <td>StratosphereLinuxIPS</td>\n",
       "      <td>stratosphereips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tests_test_database.py</td>\n",
       "      <td>test_getProfileIdFromIP</td>\n",
       "      <td>[{'commit_date_time': '2024-01-27 22:28:53+02:...</td>\n",
       "      <td>def test_getProfileIdFromIP():\\n      \\n  \\n...</td>\n",
       "      <td>- unit test for addProfile and getProfileIdFro...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tests/test_database.py</td>\n",
       "      <td>test_database.py</td>\n",
       "      <td>StratosphereLinuxIPS</td>\n",
       "      <td>stratosphereips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erpnext_stock_doctype_delivery_trip_delivery_t...</td>\n",
       "      <td>DeliveryTrip.get_directions</td>\n",
       "      <td>[{'commit_date_time': '2021-11-05 11:16:29+05:...</td>\n",
       "      <td>def get_directions(self, route, optimize):\\n...</td>\n",
       "      <td>Retrieve map directions for a given route an...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>erpnext/stock/doctype/delivery_trip/delivery_t...</td>\n",
       "      <td>delivery_trip.py</td>\n",
       "      <td>erpnext</td>\n",
       "      <td>frappe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>torch_ao_quantization_fx__model_report_detecto...</td>\n",
       "      <td>PerChannelDetector.determine_observer_insert_p...</td>\n",
       "      <td>[{'commit_date_time': '2022-06-22 12:41:22+00:...</td>\n",
       "      <td>- def determine_observer_insert_points(self, m...</td>\n",
       "      <td>r\"\"\"\\n-         There is no observers insert...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>torch/ao/quantization/fx/_model_report/detecto...</td>\n",
       "      <td>detector.py</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torch_ao_quantization_fx__model_report_detecto...</td>\n",
       "      <td>InputWeightEqualizationDetector.generate_detec...</td>\n",
       "      <td>[{'commit_date_time': '2022-12-16 08:09:33+00:...</td>\n",
       "      <td>def generate_detector_report(self, model: Gr...</td>\n",
       "      <td>r\"\"\"\\n          Determines whether input wei...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>torch/ao/quantization/fx/_model_report/detecto...</td>\n",
       "      <td>detector.py</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>zipline_algorithm.py</td>\n",
       "      <td>TradingAlgorithm.order_target_value</td>\n",
       "      <td>[{'commit_date_time': '2015-06-11 10:14:07-04:...</td>\n",
       "      <td>def order_target_value(self, sid, target,\\n ...</td>\n",
       "      <td>Place an order to adjust a position to a tar...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zipline/algorithm.py</td>\n",
       "      <td>algorithm.py</td>\n",
       "      <td>zipline</td>\n",
       "      <td>quantopian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>zipline_algorithm.py</td>\n",
       "      <td>TradingAlgorithm._create_generator</td>\n",
       "      <td>[{'commit_date_time': '2013-03-20 12:12:33-04:...</td>\n",
       "      <td>- def _create_generator(self, sim_params):\\n+ ...</td>\n",
       "      <td>Create a basic generator setup using the sou...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zipline/algorithm.py</td>\n",
       "      <td>algorithm.py</td>\n",
       "      <td>zipline</td>\n",
       "      <td>quantopian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>zipline_algorithm.py</td>\n",
       "      <td>TradingAlgorithm.symbol</td>\n",
       "      <td>[{'commit_date_time': '2018-07-18 10:14:07-04:...</td>\n",
       "      <td>- def symbol(self, symbol_str):\\n+ def symbol(...</td>\n",
       "      <td>Lookup an Equity by its ticker symbol.\\n  \\n...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zipline/algorithm.py</td>\n",
       "      <td>algorithm.py</td>\n",
       "      <td>zipline</td>\n",
       "      <td>quantopian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>zipline_algorithm.py</td>\n",
       "      <td>TradingAlgorithm.continuous_future</td>\n",
       "      <td>[{'commit_date_time': '2017-03-29 08:49:12-04:...</td>\n",
       "      <td>def continuous_future(self,\\n               ...</td>\n",
       "      <td>Create a specifier for a continuous contract...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zipline/algorithm.py</td>\n",
       "      <td>algorithm.py</td>\n",
       "      <td>zipline</td>\n",
       "      <td>quantopian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>zipline_algorithm.py</td>\n",
       "      <td>TradingAlgorithm.order_percent</td>\n",
       "      <td>[{'commit_date_time': '2015-02-17 11:50:20-05:...</td>\n",
       "      <td>def order_percent(self, sid, percent,\\n+    ...</td>\n",
       "      <td>Place an order in the specified security cor...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zipline/algorithm.py</td>\n",
       "      <td>algorithm.py</td>\n",
       "      <td>zipline</td>\n",
       "      <td>quantopian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2273 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file  \\\n",
       "0                                tests_test_database.py   \n",
       "1                                tests_test_database.py   \n",
       "2     erpnext_stock_doctype_delivery_trip_delivery_t...   \n",
       "3     torch_ao_quantization_fx__model_report_detecto...   \n",
       "4     torch_ao_quantization_fx__model_report_detecto...   \n",
       "...                                                 ...   \n",
       "2268                               zipline_algorithm.py   \n",
       "2269                               zipline_algorithm.py   \n",
       "2270                               zipline_algorithm.py   \n",
       "2271                               zipline_algorithm.py   \n",
       "2272                               zipline_algorithm.py   \n",
       "\n",
       "                                               function  \\\n",
       "0                                      test_timewindows   \n",
       "1                               test_getProfileIdFromIP   \n",
       "2                           DeliveryTrip.get_directions   \n",
       "3     PerChannelDetector.determine_observer_insert_p...   \n",
       "4     InputWeightEqualizationDetector.generate_detec...   \n",
       "...                                                 ...   \n",
       "2268                TradingAlgorithm.order_target_value   \n",
       "2269                 TradingAlgorithm._create_generator   \n",
       "2270                            TradingAlgorithm.symbol   \n",
       "2271                 TradingAlgorithm.continuous_future   \n",
       "2272                     TradingAlgorithm.order_percent   \n",
       "\n",
       "                                           version_data  \\\n",
       "0     [{'commit_date_time': '2021-08-09 21:00:11+02:...   \n",
       "1     [{'commit_date_time': '2024-01-27 22:28:53+02:...   \n",
       "2     [{'commit_date_time': '2021-11-05 11:16:29+05:...   \n",
       "3     [{'commit_date_time': '2022-06-22 12:41:22+00:...   \n",
       "4     [{'commit_date_time': '2022-12-16 08:09:33+00:...   \n",
       "...                                                 ...   \n",
       "2268  [{'commit_date_time': '2015-06-11 10:14:07-04:...   \n",
       "2269  [{'commit_date_time': '2013-03-20 12:12:33-04:...   \n",
       "2270  [{'commit_date_time': '2018-07-18 10:14:07-04:...   \n",
       "2271  [{'commit_date_time': '2017-03-29 08:49:12-04:...   \n",
       "2272  [{'commit_date_time': '2015-02-17 11:50:20-05:...   \n",
       "\n",
       "                                              diff_code  \\\n",
       "0       def test_timewindows(database):\\n        \\n-...   \n",
       "1       def test_getProfileIdFromIP():\\n      \\n  \\n...   \n",
       "2       def get_directions(self, route, optimize):\\n...   \n",
       "3     - def determine_observer_insert_points(self, m...   \n",
       "4       def generate_detector_report(self, model: Gr...   \n",
       "...                                                 ...   \n",
       "2268    def order_target_value(self, sid, target,\\n ...   \n",
       "2269  - def _create_generator(self, sim_params):\\n+ ...   \n",
       "2270  - def symbol(self, symbol_str):\\n+ def symbol(...   \n",
       "2271    def continuous_future(self,\\n               ...   \n",
       "2272    def order_percent(self, sid, percent,\\n+    ...   \n",
       "\n",
       "                                         diff_docstring  whitespace_only_code  \\\n",
       "0     - unit tests for addNewTW and getFirstTWforPro...                 False   \n",
       "1     - unit test for addProfile and getProfileIdFro...                 False   \n",
       "2       Retrieve map directions for a given route an...                 False   \n",
       "3       r\"\"\"\\n-         There is no observers insert...                 False   \n",
       "4       r\"\"\"\\n          Determines whether input wei...                 False   \n",
       "...                                                 ...                   ...   \n",
       "2268    Place an order to adjust a position to a tar...                 False   \n",
       "2269    Create a basic generator setup using the sou...                 False   \n",
       "2270    Lookup an Equity by its ticker symbol.\\n  \\n...                 False   \n",
       "2271    Create a specifier for a continuous contract...                 False   \n",
       "2272    Place an order in the specified security cor...                 False   \n",
       "\n",
       "      whitespace_only_docstring  \\\n",
       "0                         False   \n",
       "1                         False   \n",
       "2                         False   \n",
       "3                         False   \n",
       "4                         False   \n",
       "...                         ...   \n",
       "2268                      False   \n",
       "2269                      False   \n",
       "2270                      False   \n",
       "2271                      False   \n",
       "2272                      False   \n",
       "\n",
       "                                              file_path          filename  \\\n",
       "0                                tests/test_database.py  test_database.py   \n",
       "1                                tests/test_database.py  test_database.py   \n",
       "2     erpnext/stock/doctype/delivery_trip/delivery_t...  delivery_trip.py   \n",
       "3     torch/ao/quantization/fx/_model_report/detecto...       detector.py   \n",
       "4     torch/ao/quantization/fx/_model_report/detecto...       detector.py   \n",
       "...                                                 ...               ...   \n",
       "2268                               zipline/algorithm.py      algorithm.py   \n",
       "2269                               zipline/algorithm.py      algorithm.py   \n",
       "2270                               zipline/algorithm.py      algorithm.py   \n",
       "2271                               zipline/algorithm.py      algorithm.py   \n",
       "2272                               zipline/algorithm.py      algorithm.py   \n",
       "\n",
       "                   project            owner  \n",
       "0     StratosphereLinuxIPS  stratosphereips  \n",
       "1     StratosphereLinuxIPS  stratosphereips  \n",
       "2                  erpnext           frappe  \n",
       "3                  pytorch          pytorch  \n",
       "4                  pytorch          pytorch  \n",
       "...                    ...              ...  \n",
       "2268               zipline       quantopian  \n",
       "2269               zipline       quantopian  \n",
       "2270               zipline       quantopian  \n",
       "2271               zipline       quantopian  \n",
       "2272               zipline       quantopian  \n",
       "\n",
       "[2273 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = '../data/raw/test.jsonl'\n",
    "train_file = '../data/raw/train.jsonl'\n",
    "\n",
    "test_df = pd.read_json(test_file, lines=True)\n",
    "train_df = pd.read_json(train_file, lines=True)\n",
    "\n",
    "train_df\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd51961d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 215\u001b[39m\n\u001b[32m    211\u001b[39m dataset_path = \u001b[33m\"\u001b[39m\u001b[33mpath/to/your/code_comment_dataset.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# You can use a larger model with these memory savings\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;66;03m# \"Salesforce/codet5p-770m\" or even \"Salesforce/codet5p-2b\" \u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m model, tokenizer = \u001b[43mfinetune_code_comment_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSalesforce/codet5p-770m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./code-comment-lora-model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    219\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# Load and use the model for inference\u001b[39;00m\n\u001b[32m    222\u001b[39m load_and_use_model(\u001b[33m\"\u001b[39m\u001b[33m./code-comment-lora-model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mfinetune_code_comment_model\u001b[39m\u001b[34m(dataset_path, model_name, output_dir)\u001b[39m\n\u001b[32m     56\u001b[39m quantization_config = BitsAndBytesConfig(\n\u001b[32m     57\u001b[39m     load_in_4bit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     58\u001b[39m     bnb_4bit_compute_dtype=torch.float16,\n\u001b[32m     59\u001b[39m     bnb_4bit_use_double_quant=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     60\u001b[39m     bnb_4bit_quant_type=\u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m )\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Load model with quantization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m model = \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     68\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Prepare model for k-bit training\u001b[39;00m\n\u001b[32m     71\u001b[39m model = prepare_model_for_kbit_training(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/music/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    563\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    568\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    570\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/music/lib/python3.12/site-packages/transformers/modeling_utils.py:262\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    264\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/music/lib/python3.12/site-packages/transformers/modeling_utils.py:3698\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   3695\u001b[39m     hf_quantizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3698\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3704\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3705\u001b[39m     torch_dtype = hf_quantizer.update_torch_dtype(torch_dtype)\n\u001b[32m   3706\u001b[39m     device_map = hf_quantizer.update_device_map(device_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/music/lib/python3.12/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:75\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     72\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing `bitsandbytes` 4-bit quantization requires Accelerate: `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_bitsandbytes_available():\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     76\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m     )\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_bnb_backend_availability\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n",
      "\u001b[31mImportError\u001b[39m: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare your dataset\n",
    "def load_dataset(file_path):\n",
    "    test_file = '../data/raw/test.jsonl'\n",
    "    train_file = '../data/raw/train.jsonl'\n",
    "\n",
    "    test_df = pd.read_json(test_file, lines=True)\n",
    "    train_df = pd.read_json(train_file, lines=True)    \n",
    "\n",
    "    # # Split into train/validation/test\n",
    "    # train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    # train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Convert to Hugging Face datasets\n",
    "    # train_dataset = Dataset.from_pandas(train_df)\n",
    "    # val_dataset = Dataset.from_pandas(val_df)\n",
    "    # test_dataset = Dataset.from_pandas(test_df)\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    val_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# 2. Tokenization functions\n",
    "def preprocess_function(examples, tokenizer, max_input_length=512, max_target_length=128):\n",
    "    inputs = examples['diff_code']\n",
    "    targets = examples['diff_docstring']\n",
    "    \n",
    "    # Add a prefix to help the model understand the task\n",
    "    model_inputs = tokenizer(\n",
    "        [\"Generate a comment for this code: \" + code for code in inputs],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets\n",
    "    labels = tokenizer(\n",
    "        targets, \n",
    "        max_length=max_target_length, \n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# 3. Main fine-tuning function with LoRA and quantization\n",
    "def finetune_code_comment_model(dataset_path, model_name=\"Salesforce/codet5p-220m\", output_dir=\"./code-comment-model\"):\n",
    "    # Load datasets\n",
    "    train_dataset, val_dataset, test_dataset = load_dataset(dataset_path)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Configure quantization\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "    \n",
    "    # Load model with quantization\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Prepare model for k-bit training\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    \n",
    "    # Define LoRA configuration\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,  # rank\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        # Target modules depend on the model architecture\n",
    "        # For CodeT5, we typically want to adapt attention layers\n",
    "        target_modules=[\"q\", \"v\", \"k\", \"o\", \"wi\", \"wo\"],\n",
    "    )\n",
    "    \n",
    "    # Apply LoRA\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    \n",
    "    # Print trainable parameters\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    # Preprocess datasets\n",
    "    tokenized_train = train_dataset.map(\n",
    "        lambda examples: preprocess_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    tokenized_val = val_dataset.map(\n",
    "        lambda examples: preprocess_function(examples, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    \n",
    "    # Data collator\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        pad_to_multiple_of=8\n",
    "    )\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",  # Match evaluation_strategy\n",
    "        learning_rate=1e-4,  # Slightly higher learning rate for LoRA\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=4,  # Further reduce memory requirements\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=3,\n",
    "        predict_with_generate=True,\n",
    "        fp16=True,  # Mixed precision training\n",
    "        report_to=\"tensorboard\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_steps=50,\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the adapter model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"Evaluating fine-tuned model...\")\n",
    "    test_results = evaluate_model(model, tokenizer, test_dataset)\n",
    "    print(f\"Test Results: {test_results}\")\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# 4. Evaluation function\n",
    "def evaluate_model(model, tokenizer, test_dataset):\n",
    "    # A simple evaluation function\n",
    "    def generate_comment(code):\n",
    "        inputs = tokenizer(\"Generate a comment for this code: \" + code, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        outputs = model.generate(**inputs, max_length=128)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Generate comments for a few examples\n",
    "    examples = test_dataset.select(range(min(5, len(test_dataset))))\n",
    "    for i, example in enumerate(examples):\n",
    "        code = example['diff_code']\n",
    "        expected = example['diff_docstring']\n",
    "        generated = generate_comment(code)\n",
    "        \n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Code: {code[:100]}...\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "        print(f\"Generated: {generated}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Here you would implement proper evaluation metrics\n",
    "    return {\"status\": \"Evaluation complete\"}\n",
    "\n",
    "# 5. Inference with the trained model\n",
    "def load_and_use_model(model_path):\n",
    "    # Load the fine-tuned model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # For inference, we can load in 8-bit to save even more memory\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_path,\n",
    "        quantization_config=quantization_config\n",
    "    )\n",
    "    \n",
    "    # Example usage\n",
    "    code_snippet = \"\"\"\n",
    "    def calculate_average(numbers):\n",
    "        total = sum(numbers)\n",
    "        return total / len(numbers)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate comment\n",
    "    inputs = tokenizer(\"Generate a comment for this code: \" + code_snippet, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=128)\n",
    "    generated_comment = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"Generated comment: {generated_comment}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# 6. Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your dataset path\n",
    "    dataset_path = \"path/to/your/code_comment_dataset.csv\"\n",
    "    \n",
    "    # You can use a larger model with these memory savings\n",
    "    # \"Salesforce/codet5p-770m\" or even \"Salesforce/codet5p-2b\" \n",
    "    model, tokenizer = finetune_code_comment_model(\n",
    "        dataset_path=dataset_path,\n",
    "        model_name=\"Salesforce/codet5p-770m\",\n",
    "        output_dir=\"./code-comment-lora-model\"\n",
    "    )\n",
    "    \n",
    "    # Load and use the model for inference\n",
    "    load_and_use_model(\"./code-comment-lora-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5071fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cpu\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/music/lib/python3.12/site-packages (2.6.0.dev20241112)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/music/lib/python3.12/site-packages (0.20.0.dev20241118)\n",
      "Requirement already satisfied: torchaudio in /opt/anaconda3/envs/music/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from torchvision) (11.1.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/music/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Installing collected packages: sympy, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0.dev20241112\n",
      "    Uninstalling torch-2.6.0.dev20241112:\n",
      "      Successfully uninstalled torch-2.6.0.dev20241112\n",
      "Successfully installed sympy-1.13.1 torch-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
